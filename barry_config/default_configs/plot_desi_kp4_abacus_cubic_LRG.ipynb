{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd74ef87-d47b-4434-8197-30e0e515cdde",
   "metadata": {},
   "source": [
    "# Plot LRG chains\n",
    "This jupyter notebook contains some code to make plots of the bestfits and contours for the abacus cubic LRG fits to both the mock mean and individual realisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ed58620-7109-4295-8290-60ab05b99780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some necessary modules\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#%pip install chainconsumer                  # Currently needed as not yet default in cosmodesi\n",
    "from chainconsumer import ChainConsumer     \n",
    "\n",
    "sys.path.append(\"../../../Barry/\")     # Change this so that it points to where you have Barry installed\n",
    "\n",
    "from barry.samplers import DynestySampler\n",
    "from barry.config import setup\n",
    "from barry.models import PowerBeutler2017, CorrBeutler2017\n",
    "from barry.datasets.dataset_power_spectrum import PowerSpectrum_DESI_KP4\n",
    "from barry.datasets.dataset_correlation_function import CorrelationFunction_DESI_KP4\n",
    "from barry.fitter import Fitter\n",
    "from barry.models.model import Correction\n",
    "from barry.utils import weighted_avg_and_cov\n",
    "\n",
    "# Read in the fitter class to get all the info on the fit\n",
    "pfn = \"./plots/desi_kp4_abacus_cubic_LRG/output/desi_kp4_abacus_cubic_LRG.fitter.pkl\"\n",
    "with open(pfn, 'rb') as pickle_file:\n",
    "    fitter = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b70228-00e1-4605-96af-6ebbad3b48e1",
   "metadata": {},
   "source": [
    "This code segment reads in the chains, plots the bestfit model vs. data and prepares stuff for contour plots and summary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b016c6a-8047-4c8f-b29c-1b2ef79ce6d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'mi' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m stats \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      9\u001b[0m output \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m posterior, weight, chain, evidence, model, data, extra \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Get the realisation number and redshift bin\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     recon_bin \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrerecon\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m extra[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     14\u001b[0m     data_bin \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXi\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m extra[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCV\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m extra[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[0;32m/global/u1/c/chowlett/desi-y1-kp45/barry_config/default_configs/../../../Barry/barry/fitter.py:289\u001b[0m, in \u001b[0;36mFitter.load\u001b[0;34m(self, split_models, split_walkers)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m         stacked \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack((stacked, c))\n\u001b[0;32m--> 289\u001b[0m results_models\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_datasets[\u001b[43mmi\u001b[49m])\n\u001b[1;32m    290\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(stacked)\n\u001b[1;32m    292\u001b[0m finals \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'mi' referenced before assignment"
     ]
    }
   ],
   "source": [
    "logging.info(\"Creating plots\")\n",
    "\n",
    "fitname = []\n",
    "datanames = [\"Xi\", \"Pk\", \"Pk_CV\"]\n",
    "c = [ChainConsumer(), ChainConsumer(), ChainConsumer(), ChainConsumer(), ChainConsumer(), ChainConsumer()]\n",
    "\n",
    "# Loop over all the chains\n",
    "stats = {}\n",
    "output = {}\n",
    "for posterior, weight, chain, evidence, model, data, extra in fitter.load():\n",
    "\n",
    "    # Get the realisation number and redshift bin\n",
    "    recon_bin = 0 if \"Prerecon\" in extra[\"name\"] else 1\n",
    "    data_bin = 0 if \"Xi\" in extra[\"name\"] else 1 if \"CV\" not in extra[\"name\"] else 2\n",
    "    realisation = str(extra[\"name\"].split()[-1]) if \"realisation\" in extra[\"name\"] else \"mean\"\n",
    "    chain_bin = int(2.0 * data_bin + recon_bin)\n",
    "    print(extra[\"name\"], recon_bin, data_bin, realisation)\n",
    "    \n",
    "    # Store the chain in a dictionary with parameter names\n",
    "    df = pd.DataFrame(chain, columns=model.get_labels())\n",
    "\n",
    "    # Compute alpha_par and alpha_perp for each point in the chain\n",
    "    alpha_par, alpha_perp = model.get_alphas(df[\"$\\\\alpha$\"].to_numpy(), df[\"$\\\\epsilon$\"].to_numpy())\n",
    "    df[\"$\\\\alpha_\\\\parallel$\"] = alpha_par\n",
    "    df[\"$\\\\alpha_\\\\perp$\"] = alpha_perp\n",
    "\n",
    "    # Get the MAP point and set the model up at this point\n",
    "    model.set_data(data)\n",
    "    r_s = model.camb.get_data()[\"r_s\"]\n",
    "    max_post = posterior.argmax()\n",
    "    params = df.loc[max_post]\n",
    "    params_dict = model.get_param_dict(chain[max_post])\n",
    "    for name, val in params_dict.items():\n",
    "        model.set_default(name, val)\n",
    "\n",
    "    # Get some useful properties of the fit, and plot the MAP model against the data if it's the mock mean or realisation 10 (chosen randomly!)\n",
    "    new_chi_squared, dof, bband, mods, smooths = model.plot(params_dict, display=True)\n",
    "\n",
    "    # Add the chain or MAP to the Chainconsumer plots\n",
    "    extra.pop(\"realisation\", None)\n",
    "    if realisation == \"mean\":\n",
    "        fitname.append(data[0][\"name\"].replace(\" \", \"_\"))\n",
    "        stats[fitname[recon_bin]] = []\n",
    "        output[fitname[recon_bin]] = []\n",
    "        c[chain_bin].add_chain(df, weights=weight, **extra, plot_contour=True, plot_point=False, show_as_1d_prior=False)\n",
    "    else:\n",
    "        c[chain_bin].add_marker(params, **extra)\n",
    "\n",
    "    # Compute some summary statistics and add them to a dictionary\n",
    "    mean, cov = weighted_avg_and_cov(\n",
    "        df[\n",
    "            [\n",
    "                \"$\\\\alpha_\\\\parallel$\",\n",
    "                \"$\\\\alpha_\\\\perp$\",\n",
    "                \"$\\\\Sigma_{nl,||}$\",\n",
    "                \"$\\\\Sigma_{nl,\\\\perp}$\",\n",
    "            ]\n",
    "        ],\n",
    "        weight,\n",
    "        axis=0,\n",
    "    )\n",
    "\n",
    "    corr = cov[1, 0] / np.sqrt(cov[0, 0] * cov[1, 1])\n",
    "    stats[fitname[recon_bin]].append(\n",
    "        [mean[0], mean[1], np.sqrt(cov[0, 0]), np.sqrt(cov[1, 1]), corr, new_chi_squared, mean[2], mean[3]]\n",
    "    )\n",
    "    output[fitname[recon_bin]].append(\n",
    "        f\"{realisation:s}, {mean[0]:6.4f}, {mean[1]:6.4f}, {mean[2]:6.4f}, {mean[3]:6.4f}, {np.sqrt(cov[0, 0]):6.4f}, {np.sqrt(cov[1, 1]):6.4f}, {corr:7.3f}, {r_s:7.3f}, {new_chi_squared:7.3f}, {dof:4d}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f473f4bf-4963-4d1b-89b8-b8781c9e731f",
   "metadata": {},
   "source": [
    "Plot the contour plots and output the summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbf08fb-9f20-4f41-b598-8b6bdc369fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = {\"$\\\\alpha$\": 1.0, \"$\\\\epsilon$\": 0, \"$\\\\alpha_\\\\perp$\": 1.0, \"$\\\\alpha_\\\\parallel$\": 1.0}\n",
    "for recon_bin in range(len(c)):\n",
    "    c[recon_bin].plotter.plot(\n",
    "        truth=truth,\n",
    "        parameters=[\"$\\\\alpha_\\\\parallel$\", \"$\\\\alpha_\\\\perp$\"],\n",
    "        legend=False,\n",
    "        display=True,\n",
    "    )\n",
    "\n",
    "    # Save all the numbers to a file\n",
    "    with open(dir_name + \"/Barry_fit_\" + fitname[recon_bin] + \".txt\", \"w\") as f:\n",
    "        f.write(\n",
    "            \"# Realisation, alpha_par, alpha_perp, Sigma_nl_par, Sigma_nl_perp, sigma_alpha_par, sigma_alpha_perp, corr_alpha_par_perp, rd_of_template, bf_chi2, dof\\n\"\n",
    "        )\n",
    "        for l in output[fitname[recon_bin]]:\n",
    "            f.write(l + \"\\n\")\n",
    "\n",
    "        # And now the average of all the individual realisations\n",
    "        f.write(\"# ---------------------------------------------------\\n\")\n",
    "        f.write(\n",
    "            \"# <alpha_par>, <alpha_perp>, <Sigma_nl_par>, <Sigma_nl_perp>, <sigma_alpha_par>, <sigma_alpha_perp>, <corr_alpha_par_perp>, std_alpha_par, std_alpha_perp, corr_alpha_par_perp, <bf_chi2>\\n\"\n",
    "        )\n",
    "        f.write(\n",
    "            f\"{means[0]:6.4f}, {means[1]:6.4f}, {means[6]:6.4f}, {means[7]:6.4f}, {means[2]:6.4f}, {means[3]:6.4f}, {means[4]:6.4f}, {np.sqrt(covs[0, 0]):6.4f}, {np.sqrt(covs[1, 1]):6.4f}, {corr:6.4f}, {means[5]:7.3f}\\n\"\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosmodesi-main",
   "language": "python",
   "name": "cosmodesi-main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
